{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:54:35.916862Z",
     "iopub.status.busy": "2025-07-14T13:54:35.916558Z",
     "iopub.status.idle": "2025-07-14T13:54:37.089194Z",
     "shell.execute_reply": "2025-07-14T13:54:37.088222Z",
     "shell.execute_reply.started": "2025-07-14T13:54:35.916838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:54:43.583435Z",
     "iopub.status.busy": "2025-07-14T13:54:43.582517Z",
     "iopub.status.idle": "2025-07-14T13:54:43.625695Z",
     "shell.execute_reply": "2025-07-14T13:54:43.624973Z",
     "shell.execute_reply.started": "2025-07-14T13:54:43.583381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "# Define file paths (Kaggle default path structure)\n",
    "TRAIN_PATH = '/kaggle/input/playground-series-s5e7/train.csv'\n",
    "TEST_PATH = '/kaggle/input/playground-series-s5e7/test.csv'\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:54:49.261861Z",
     "iopub.status.busy": "2025-07-14T13:54:49.261522Z",
     "iopub.status.idle": "2025-07-14T13:54:49.275382Z",
     "shell.execute_reply": "2025-07-14T13:54:49.274328Z",
     "shell.execute_reply.started": "2025-07-14T13:54:49.261834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Basic Preprocessing\n",
    "\n",
    "# Drop the 'id' column as it's not predictive\n",
    "train_df.drop(columns=['id'], inplace=True)\n",
    "test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Method to splits df into numerical and categorical features.\n",
    "def split_numerical_categorical(df):\n",
    "    \"\"\"\n",
    "    Splits the columns of a DataFrame into numerical and categorical features.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to split.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two lists - numerical columns and categorical columns.\n",
    "    \"\"\"\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "    return numerical_cols, categorical_cols\n",
    "\n",
    "# Separate target variable\n",
    "target = train_df['Personality']\n",
    "train_df.drop(columns=['Personality'], inplace=True)\n",
    "\n",
    "# Split features into numerical and categorical using a custom utility\n",
    "numerical_cols, categorical_cols = split_numerical_categorical(train_df)\n",
    "\n",
    "print(\"Numerical features:\", numerical_cols)\n",
    "print(\"Categorical features:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:55:09.819919Z",
     "iopub.status.busy": "2025-07-14T13:55:09.819230Z",
     "iopub.status.idle": "2025-07-14T13:55:09.882672Z",
     "shell.execute_reply": "2025-07-14T13:55:09.881784Z",
     "shell.execute_reply.started": "2025-07-14T13:55:09.819876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Stage 4: Handle Missing Values\n",
    "# ==========================================\n",
    "# Combine train and test for consistent preprocessing\n",
    "full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Impute missing numerical values using Iterative Imputer (e.g., Bayesian Ridge)\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "full[numerical_cols] = imputer.fit_transform(full[numerical_cols])\n",
    "\n",
    "# Imputer for categorical columns with constant value 'Missing'\n",
    "imputer_const = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "\n",
    "# Apply imputation and preserve column names\n",
    "full_df[categorical_cols] = pd.DataFrame(\n",
    "    imputer_const.fit_transform(full_df[categorical_cols]),\n",
    "    columns=categorical_cols,\n",
    "    index=full_df.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:55:15.511790Z",
     "iopub.status.busy": "2025-07-14T13:55:15.511446Z",
     "iopub.status.idle": "2025-07-14T13:55:15.528767Z",
     "shell.execute_reply": "2025-07-14T13:55:15.527966Z",
     "shell.execute_reply.started": "2025-07-14T13:55:15.511764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode Categorical Features\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features\n",
    "full_encoded = pd.get_dummies(full_df, columns=categorical_cols)\n",
    "\n",
    "# Split the combined data back into training and test sets\n",
    "X_train = full_encoded.iloc[:len(train_df)]\n",
    "X_test = full_encoded.iloc[len(train_df):]\n",
    "y_train = target.map({'Extrovert': 0, 'Introvert': 1})  # Encode target as binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:55:22.882111Z",
     "iopub.status.busy": "2025-07-14T13:55:22.881765Z",
     "iopub.status.idle": "2025-07-14T13:56:04.413869Z",
     "shell.execute_reply": "2025-07-14T13:56:04.412743Z",
     "shell.execute_reply.started": "2025-07-14T13:55:22.882086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#LightGBM\n",
    "\n",
    "%pip install optuna  \n",
    "\n",
    "\n",
    "# 1. Imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# 2. Optuna - Hyperparameter Optimization for LightGBM\n",
    "def objective_lgbm(trial):\n",
    "    # Define the hyperparameter search space for LightGBM\n",
    "    param_lgbm = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Stratified K-Fold to preserve label distribution across folds\n",
    "    skf_lgbm = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores_lgbm = []\n",
    "\n",
    "    for train_idx, val_idx in skf_lgbm.split(X_train, y_train):\n",
    "        # Split training and validation data for each fold\n",
    "        X_tr_lgbm, X_val_lgbm = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr_lgbm, y_val_lgbm = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Initialize and train LightGBM model with current parameters\n",
    "        model_lgbm = lgb.LGBMClassifier(**param_lgbm, verbose = -1)\n",
    "        model_lgbm.fit(\n",
    "            X_tr_lgbm, y_tr_lgbm,\n",
    "            eval_set=[(X_val_lgbm, y_val_lgbm)],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        # Predict on validation set and compute accuracy\n",
    "        val_pred_lgbm = model_lgbm.predict(X_val_lgbm)\n",
    "        score_lgbm = accuracy_score(y_val_lgbm, val_pred_lgbm)\n",
    "        scores_lgbm.append(score_lgbm)\n",
    "    \n",
    "    # Return mean cross-validation score\n",
    "    return np.mean(scores_lgbm)\n",
    "\n",
    "# Run Optuna study with the defined objective\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=30)  # Increase n_trials for better optimization\n",
    "\n",
    "# Display best hyperparameters found by Optuna\n",
    "print(\"Best hyperparameters found by Optuna:\", study_lgbm.best_params)\n",
    "\n",
    "# 3. Train Final Model with Out-of-Fold (OOF) and Test Predictions\n",
    "best_params_lgbm = study_lgbm.best_params\n",
    "best_params_lgbm.update({'random_state': 42, 'n_jobs': -1})\n",
    "\n",
    "# Use 10-fold Stratified CV for final training and predictions\n",
    "skf_lgbm = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_lgbm = []\n",
    "\n",
    "# Initialize arrays to store predictions\n",
    "test_preds_lgbm = np.zeros((len(X_test), skf_lgbm.n_splits))  # Test predictions per fold\n",
    "oof_preds_lgbm = np.zeros(len(X_train))                       # Out-of-fold predictions\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_lgbm.split(X_train, y_train)):\n",
    "    # Split data into train and validation sets\n",
    "    X_tr_lgbm, X_val_lgbm = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr_lgbm, y_val_lgbm = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Train model with best parameters from Optuna\n",
    "    model_lgbm = lgb.LGBMClassifier(**best_params_lgbm)\n",
    "    model_lgbm.fit(\n",
    "        X_tr_lgbm, y_tr_lgbm,\n",
    "        eval_set=[(X_val_lgbm, y_val_lgbm)],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Predict and evaluate on validation set\n",
    "    val_pred_lgbm = model_lgbm.predict(X_val_lgbm)\n",
    "    score_lgbm = accuracy_score(y_val_lgbm, val_pred_lgbm)\n",
    "    scores_lgbm.append(score_lgbm)\n",
    "    \n",
    "    # Store OOF predicted probabilities for ensemble/blending\n",
    "    oof_preds_lgbm[val_idx] = model_lgbm.predict_proba(X_val_lgbm)[:, 1]\n",
    "    \n",
    "    # Store predictions on test set for this fold\n",
    "    test_preds_lgbm[:, fold] = model_lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert OOF probabilities to binary predictions using 0.5 threshold\n",
    "oof_binary_lgbm = (oof_preds_lgbm > 0.5).astype(int)\n",
    "print(\"OOF accuracy:\", accuracy_score(y_train, oof_binary_lgbm))\n",
    "\n",
    "# Average test predictions across all folds\n",
    "mean_preds_lgbm = test_preds_lgbm.mean(axis=1)\n",
    "final_test_pred_lgbm = (mean_preds_lgbm > 0.5).astype(int)\n",
    "\n",
    "# Print individual fold accuracies and overall mean CV score\n",
    "print(f'Fold accuracies: {scores_lgbm}')\n",
    "print(f'Mean CV accuracy: {np.mean(scores_lgbm):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:56:06.741257Z",
     "iopub.status.busy": "2025-07-14T13:56:06.740268Z",
     "iopub.status.idle": "2025-07-14T13:57:22.922527Z",
     "shell.execute_reply": "2025-07-14T13:57:22.921344Z",
     "shell.execute_reply.started": "2025-07-14T13:56:06.741227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#catboost\n",
    "\n",
    "%pip install catboost \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_features_cat = []  # <- Set to column indices/names if you have categorical features\n",
    "\n",
    "# 1. Optuna - Hyperparameter Optimization for CatBoost\n",
    "def objective_cat(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    param_cat = {\n",
    "        'iterations': trial.suggest_int('iterations', 200, 1200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.1, 2.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,  # Suppress CatBoost training output\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'Accuracy',\n",
    "        'cat_features': cat_features_cat\n",
    "    }\n",
    "\n",
    "    # Perform 5-fold stratified cross-validation\n",
    "    skf_cat = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores_cat = []\n",
    "\n",
    "    for train_idx, val_idx in skf_cat.split(X_train, y_train):\n",
    "        # Split data into training and validation sets\n",
    "        X_tr_cat, X_val_cat = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr_cat, y_val_cat = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Train the CatBoost model with the current hyperparameters\n",
    "        model_cat = CatBoostClassifier(**param_cat)\n",
    "        model_cat.fit(\n",
    "            X_tr_cat, y_tr_cat,\n",
    "            eval_set=(X_val_cat, y_val_cat),\n",
    "            early_stopping_rounds=50,\n",
    "            use_best_model=True\n",
    "        )\n",
    "        \n",
    "        # Evaluate model on validation data\n",
    "        val_pred_cat = model_cat.predict(X_val_cat)\n",
    "        score_cat = accuracy_score(y_val_cat, val_pred_cat)\n",
    "        scores_cat.append(score_cat)\n",
    "    \n",
    "    # Return the average validation score across folds\n",
    "    return np.mean(scores_cat)\n",
    "\n",
    "# Run the Optuna study to maximize the validation accuracy\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat, n_trials=30)  # Increase n_trials for more thorough optimization\n",
    "\n",
    "# Print the best hyperparameters found by Optuna\n",
    "print(\"Best hyperparameters found by Optuna:\", study_cat.best_params)\n",
    "\n",
    "# 2. Train Final Model Using Out-of-Fold (OOF) and Test Predictions\n",
    "\n",
    "# Prepare best parameters and update with fixed values\n",
    "best_params_cat = study_cat.best_params\n",
    "best_params_cat.update({\n",
    "    'random_seed': 42,\n",
    "    'verbose': 0,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'cat_features': cat_features_cat\n",
    "})\n",
    "\n",
    "# Use 10-fold stratified cross-validation for final model evaluation\n",
    "skf_cat = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_cat = []\n",
    "\n",
    "# Arrays to store predictions\n",
    "test_preds_cat = np.zeros((len(X_test), skf_cat.n_splits))  # Predictions for each test fold\n",
    "oof_preds_cat = np.zeros(len(X_train))                       # Out-of-Fold predictions for training data\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_cat.split(X_train, y_train)):\n",
    "    # Split data into training and validation sets\n",
    "    X_tr_cat, X_val_cat = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr_cat, y_val_cat = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # Train model using best parameters\n",
    "    model_cat = CatBoostClassifier(**best_params_cat)\n",
    "    model_cat.fit(\n",
    "        X_tr_cat, y_tr_cat,\n",
    "        eval_set=(X_val_cat, y_val_cat),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    \n",
    "    # Validation accuracy\n",
    "    val_pred_cat = model_cat.predict(X_val_cat)\n",
    "    score_cat = accuracy_score(y_val_cat, val_pred_cat)\n",
    "    scores_cat.append(score_cat)\n",
    "    \n",
    "    # Store Out-of-Fold predicted probabilities\n",
    "    oof_preds_cat[val_idx] = model_cat.predict_proba(X_val_cat)[:, 1]\n",
    "    \n",
    "    # Store predicted probabilities for the test set (per fold)\n",
    "    test_preds_cat[:, fold] = model_cat.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert OOF probabilities into binary predictions using 0.5 threshold\n",
    "oof_binary_cat = (oof_preds_cat > 0.5).astype(int)\n",
    "print(\"OOF accuracy:\", accuracy_score(y_train, oof_binary_cat))\n",
    "\n",
    "# Average the test predictions across all folds\n",
    "mean_preds_cat = test_preds_cat.mean(axis=1)\n",
    "final_test_pred_cat = (mean_preds_cat > 0.5).astype(int)\n",
    "\n",
    "# Print fold-wise and mean cross-validation accuracy\n",
    "print(f'Fold accuracy: {scores_cat}')\n",
    "print(f'Mean CV accuracy: {np.mean(scores_cat):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:57:42.109294Z",
     "iopub.status.busy": "2025-07-14T13:57:42.108395Z",
     "iopub.status.idle": "2025-07-14T13:58:20.915653Z",
     "shell.execute_reply": "2025-07-14T13:58:20.914703Z",
     "shell.execute_reply.started": "2025-07-14T13:57:42.109260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 1. Optuna - hyperparameter optimization\n",
    "def objective_xgb(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    param_xgb = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss',\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "\n",
    "    # 5-fold Stratified Cross-Validation\n",
    "    skf_xgb = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores_xgb = []\n",
    "\n",
    "    for train_idx, val_idx in skf_xgb.split(X_train, y_train):\n",
    "        # Split training and validation data\n",
    "        X_tr_xgb, X_val_xgb = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr_xgb, y_val_xgb = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Train the XGBoost model with current hyperparameters\n",
    "        model_xgb = xgb.XGBClassifier(**param_xgb)\n",
    "        model_xgb.fit(\n",
    "            X_tr_xgb, y_tr_xgb,\n",
    "            eval_set=[(X_val_xgb, y_val_xgb)],\n",
    "            verbose=False  # Suppress output\n",
    "        )\n",
    "\n",
    "        # Evaluate accuracy and store the result\n",
    "        scores_xgb.append(accuracy_score(y_val_xgb, model_xgb.predict(X_val_xgb)))\n",
    "\n",
    "    # Return mean cross-validation score\n",
    "    return np.mean(scores_xgb)\n",
    "\n",
    "# Run Optuna optimization process\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "# Prepare final best parameters for training\n",
    "best_params_xgb = study_xgb.best_params\n",
    "best_params_xgb.update({\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss',\n",
    "    'early_stopping_rounds': 50\n",
    "})\n",
    "\n",
    "# 10-fold Stratified Cross-Validation for final training and evaluation\n",
    "skf_xgb = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_xgb = []\n",
    "\n",
    "# Arrays to hold predictions\n",
    "test_preds_xgb = np.zeros((len(X_test), skf_xgb.n_splits))  # Test set predictions\n",
    "oof_preds_xgb = np.zeros(len(X_train))                      # Out-of-fold predictions\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_xgb.split(X_train, y_train)):\n",
    "    # Split into training and validation sets for this fold\n",
    "    X_tr_xgb, X_val_xgb = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr_xgb, y_val_xgb = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    # Train the model using best parameters\n",
    "    model_xgb = xgb.XGBClassifier(**best_params_xgb)\n",
    "    model_xgb.fit(\n",
    "        X_tr_xgb, y_tr_xgb,\n",
    "        eval_set=[(X_val_xgb, y_val_xgb)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Save fold accuracy\n",
    "    scores_xgb.append(accuracy_score(y_val_xgb, model_xgb.predict(X_val_xgb)))\n",
    "\n",
    "    # Save OOF predictions (probability for class 1)\n",
    "    oof_preds_xgb[val_idx] = model_xgb.predict_proba(X_val_xgb)[:, 1]\n",
    "\n",
    "    # Save test set predictions for this fold\n",
    "    test_preds_xgb[:, fold] = model_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Convert OOF probabilities to binary predictions using 0.5 threshold\n",
    "oof_binary_xgb = (oof_preds_xgb > 0.5).astype(int)\n",
    "\n",
    "# Evaluate OOF accuracy\n",
    "print(\"OOF accuracy:\", accuracy_score(y_train, oof_binary_xgb))\n",
    "\n",
    "# Print accuracy for each fold\n",
    "mean_score_xgb = np.mean(scores_xgb)\n",
    "print(\"Fold accuracy:\", scores_xgb)\n",
    "print(f\"Mean CV accuracy: {mean_score_xgb:.4f}\")\n",
    "\n",
    "# Average predictions across all folds for final test prediction\n",
    "mean_preds_xgb = test_preds_xgb.mean(axis=1)\n",
    "final_test_pred_xgb = (mean_preds_xgb > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:58:27.209046Z",
     "iopub.status.busy": "2025-07-14T13:58:27.208729Z",
     "iopub.status.idle": "2025-07-14T13:58:27.235183Z",
     "shell.execute_reply": "2025-07-14T13:58:27.234375Z",
     "shell.execute_reply.started": "2025-07-14T13:58:27.209021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ===== OOF predictions ensemble (averaging predictions across models) =====\n",
    "# Combine out-of-fold predictions from LightGBM, CatBoost, and XGBoost by averaging\n",
    "oof_preds_ensemble = (oof_preds_lgbm + oof_preds_cat + oof_preds_xgb) / 3\n",
    "\n",
    "# Convert averaged probabilities to binary predictions using a 0.5 threshold\n",
    "oof_binary_ensemble = (oof_preds_ensemble > 0.5).astype(int)\n",
    "\n",
    "# Calculate overall OOF accuracy for the ensemble\n",
    "oof_accuracy_ensemble = accuracy_score(y_train, oof_binary_ensemble)\n",
    "print(\"OOF accuracy (ensemble):\", oof_accuracy_ensemble)\n",
    "\n",
    "# ===== CV accuracy per fold (based on ensemble OOF predictions) =====\n",
    "# Perform Stratified K-Fold to evaluate ensemble accuracy fold by fold\n",
    "skf_ensemble = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores_ensemble = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf_ensemble.split(X_train, y_train)):\n",
    "    # Average the OOF predictions for the current fold from all models\n",
    "    oof_fold = (oof_preds_lgbm[val_idx] + oof_preds_cat[val_idx] + oof_preds_xgb[val_idx]) / 3\n",
    "    \n",
    "    # Convert probabilities to binary predictions\n",
    "    oof_fold_binary = (oof_fold > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate accuracy for the current fold\n",
    "    acc = accuracy_score(np.array(y_train)[val_idx], oof_fold_binary)\n",
    "    cv_scores_ensemble.append(acc)\n",
    "\n",
    "# Calculate mean cross-validation accuracy across all folds\n",
    "mean_cv_accuracy_ensemble = np.mean(cv_scores_ensemble)\n",
    "print(f\"Fold accuracy (ensemble): {cv_scores_ensemble}\")\n",
    "print(f\"Mean CV accuracy (ensemble): {mean_cv_accuracy_ensemble:.4f}\")\n",
    "\n",
    "# ===== Test predictions ensemble (average predictions across models and folds) =====\n",
    "# Average test predictions over folds for each model\n",
    "mean_preds_lgbm = test_preds_lgbm.mean(axis=1)\n",
    "mean_preds_cat = test_preds_cat.mean(axis=1)\n",
    "mean_preds_xgb = test_preds_xgb.mean(axis=1)\n",
    "\n",
    "# Combine predictions from all three models by averaging\n",
    "ensemble_test = (mean_preds_lgbm + mean_preds_cat + mean_preds_xgb) / 3\n",
    "\n",
    "# Final binary predictions on the test set using a 0.5 threshold\n",
    "final_ensemble_pred = (ensemble_test > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T13:58:42.190621Z",
     "iopub.status.busy": "2025-07-14T13:58:42.190089Z",
     "iopub.status.idle": "2025-07-14T13:58:42.211487Z",
     "shell.execute_reply": "2025-07-14T13:58:42.210436Z",
     "shell.execute_reply.started": "2025-07-14T13:58:42.190593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert binary predictions (0,1) to string labels ('Extrovert', 'Introvert')\n",
    "final_ensemble_pred_labels = pd.Series(final_ensemble_pred).map({0: 'Extrovert', 1: 'Introvert'}).values\n",
    "\n",
    "# Load the sample submission file which contains the required format and IDs\n",
    "ssub = pd.read_csv(\"/kaggle/input/playground-series-s5e7/sample_submission.csv\")\n",
    "\n",
    "# Replace the 'Personality' column with our predicted personality labels\n",
    "ssub['Personality'] = final_ensemble_pred_labels\n",
    "\n",
    "# Save the updated DataFrame to a CSV file without including the index\n",
    "ssub.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12738969,
     "sourceId": 91718,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
