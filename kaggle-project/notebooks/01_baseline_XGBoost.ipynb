{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline — Playground Series S5E7\n",
    "Pierwsze podejście: Baseline - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dodaj src do sys.path, by importować własne moduły\n",
    "sys.path.append('../src')\n",
    "\n",
    "from experiment_logger import log_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18524, 9)\n",
      "Test shape: (6175, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Time_spent_Alone</th>\n",
       "      <th>Stage_fear</th>\n",
       "      <th>Social_event_attendance</th>\n",
       "      <th>Going_outside</th>\n",
       "      <th>Drained_after_socializing</th>\n",
       "      <th>Friends_circle_size</th>\n",
       "      <th>Post_frequency</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Introvert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Extrovert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
       "0   0               0.0         No                      6.0            4.0   \n",
       "1   1               1.0         No                      7.0            3.0   \n",
       "2   2               6.0        Yes                      1.0            0.0   \n",
       "3   3               3.0         No                      7.0            3.0   \n",
       "4   4               1.0         No                      4.0            4.0   \n",
       "\n",
       "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \n",
       "0                        No                 15.0             5.0   Extrovert  \n",
       "1                        No                 10.0             8.0   Extrovert  \n",
       "2                       NaN                  3.0             0.0   Introvert  \n",
       "3                        No                 11.0             5.0   Extrovert  \n",
       "4                        No                 13.0             NaN   Extrovert  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH = '../../playground-series-s5e7/train.csv'\n",
    "TEST_PATH = '../../playground-series-s5e7/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print('Train shape:', train_data.shape)\n",
    "print('Test shape:', test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "Time_spent_Alone             1190\n",
       "Stage_fear                   1893\n",
       "Social_event_attendance      1180\n",
       "Going_outside                1466\n",
       "Drained_after_socializing    1149\n",
       "Friends_circle_size          1054\n",
       "Post_frequency               1264\n",
       "Personality                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "Time_spent_Alone             425\n",
       "Stage_fear                   598\n",
       "Social_event_attendance      397\n",
       "Going_outside                466\n",
       "Drained_after_socializing    432\n",
       "Friends_circle_size          350\n",
       "Post_frequency               408\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18524 entries, 0 to 18523\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         18524 non-null  int64  \n",
      " 1   Time_spent_Alone           17334 non-null  float64\n",
      " 2   Stage_fear                 16631 non-null  object \n",
      " 3   Social_event_attendance    17344 non-null  float64\n",
      " 4   Going_outside              17058 non-null  float64\n",
      " 5   Drained_after_socializing  17375 non-null  object \n",
      " 6   Friends_circle_size        17470 non-null  float64\n",
      " 7   Post_frequency             17260 non-null  float64\n",
      " 8   Personality                18524 non-null  object \n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Personality\n",
       "Extrovert    0.739527\n",
       "Introvert    0.260473\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.info()\n",
    "train_data.describe()\n",
    "train_data['Personality'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['id'], inplace=True)\n",
    "test_data.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zmienne numeryczne: ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
      "Zmienne kategoryczne: ['Stage_fear_Yes', 'Drained_after_socializing_Yes']\n",
      "Kolumny w full: ['Time_spent_Alone', 'Stage_fear', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency']\n",
      "Kolumny kategorialne: ['Stage_fear_Yes', 'Drained_after_socializing_Yes']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Stage_fear_Yes', 'Drained_after_socializing_Yes'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKolumny kategorialne:\u001b[39m\u001b[33m\"\u001b[39m, categorical_cols)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# One-hot encoding\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m full_encoded = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Rozdzielamy z powrotem\u001b[39;00m\n\u001b[32m     21\u001b[39m X_train = full_encoded.iloc[:\u001b[38;5;28mlen\u001b[39m(train_data)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:169\u001b[39m, in \u001b[36mget_dummies\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput must be a list-like for parameter `columns`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     data_to_encode = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Stage_fear_Yes', 'Drained_after_socializing_Yes'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Załóżmy, że usunąłeś już kolumnę 'id' z train i test\n",
    "from data_utils import split_numerical_categorical\n",
    "\n",
    "# Zakładam, że X_train to Twój DataFrame z cechami (bez targetu i id)\n",
    "numerical_cols, categorical_cols = split_numerical_categorical(X_train)\n",
    "\n",
    "print(\"Zmienne numeryczne:\", numerical_cols)\n",
    "print(\"Zmienne kategoryczne:\", categorical_cols)\n",
    "\n",
    "# Łączymy train i test, by mieć spójny encoding\n",
    "target = train_data['Personality']\n",
    "full = pd.concat([train_data.drop('Personality', axis=1), test_data], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Kolumny w full:\", full.columns.tolist())\n",
    "print(\"Kolumny kategorialne:\", categorical_cols)\n",
    "\n",
    "# One-hot encoding\n",
    "full_encoded = pd.get_dummies(full, columns=categorical_cols)\n",
    "\n",
    "# Rozdzielamy z powrotem\n",
    "X_train = full_encoded.iloc[:len(train_data)]\n",
    "X_test = full_encoded.iloc[len(train_data):]\n",
    "y_train = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18524, 7)\n",
      "(6175, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4342, number of negative: 12329\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 67\n",
      "[LightGBM] [Info] Number of data points in the train set: 16671, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.260452 -> initscore=-1.043619\n",
      "[LightGBM] [Info] Start training from score -1.043619\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.127479\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Extrovert'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     scores.append(score)\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Predykcje na test dla każdego folda (do uśrednienia)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mtest_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m]\u001b[49m = model.predict(X_test)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFold accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mMean CV accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Extrovert'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import numpy as np\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "test_preds = np.zeros((len(X_test), 10))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(50), log_evaluation(0)]\n",
    ")\n",
    "    \n",
    "    val_pred = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, val_pred)\n",
    "    scores.append(score)\n",
    "    \n",
    "    # Predykcje na test dla każdego folda (do uśrednienia)\n",
    "    test_preds[:, fold] = model.predict(X_test)\n",
    "\n",
    "print(f'Fold accuracy: {scores}')\n",
    "print(f'Mean CV accuracy: {np.mean(scores):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
